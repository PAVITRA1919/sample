class Node:
  def __init__(self,name,value):
    self.name=name
    self.value=value    #information gain
    self.children=[]
    
  def add_children(self,node):
    self.children.append(node)

  def Print_node(self):
    print(self.name)
    for x in self.children:
      Node.Print_node(x)



class Tree:
  def __init__(self,node):
    self.root=node
  def Print_tree(self):
    self.root.Print_node()


root=Node('r','5')
left=Node('c1','4')
right=Node('c2','3')
root.add_children(left)
root.add_children(right)
tree=Tree(root)
tree.Print_tree()


mport math
class DescisionTree:
  def entropy(self,p):
    if p==0 or p==1:
      return 0
    x=-((p*math.log2(p))+((1-p)*math.log2(1-p)))
    return x
  
  def calculate_p(self,dataset,feature):
    n = len(dataset)
    # count the occurence of each value in a featre
    count={}
    d = dataset[feature]
    for  val in d:
      
      if val in count:
        count[val] += 1
      else:
        count[val]=1

  #calculate probability of each item by dividing occurences with total instances in data set

    probability = {}
    for val,counter in count.items():
      probability[val] = counter/n
    return probability


Info(p,A)=E(p)−E(p|A) 

E(p)=−∑i=1npilog2pi 
E(p|A)=∑i=1npiE(p|A=ai) 


rom google.colab import drive
drive.mount('/content/drive')
path='/content/drive/MyDrive/MachineLearning/09-01-2023/tennis.csv'


import pandas as pd
!ls
df=pd.read_csv(path)
df

df['wind']
dt=DescisionTree()
p=dt.calculate_p(df,'wind')
print(p)
x=dt.entropy(p['Weak'])

print(x)


#graphviz
import graphviz
d = graphviz.Digraph(filename='rank_same.gv')
with d.subgraph() as s:
  s.attr(rank='same')
  s.node('A')
  s.node('X')
d.node('C')
with d.subgraph() as s:
  s.attr(rank='same')
  s.node('B')
  s.node('D')
  s.node('Y')
d.edges(['AB','CD','XY'])
d.edge('A','C',label='A=0')
d.edge('D','B',label='K=50')
d


from google.colab import drive
drive.mount('/content/drive')
path='/content/drive/MyDrive/MachineLearning/09-01-2023/tennis.csv'


import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import math
import copy
l=[]
gain=[]
dataset = pd.read_csv(path)
X = dataset.iloc[:, 1:].values
attribute = ['outlook', 'temp', 'humidity', 'wind']


class Node(object):
    def __init__(self):
        self.value = None
        self.decision = None
        self.childs = None


def findEntropy(data, rows):
    yes = 0
    no = 0
    ans = -1
    idx = len(data[0]) - 1
    entropy = 0
    for i in rows:
        if data[i][idx] == 'Yes':
            yes = yes + 1
        else:
            no = no + 1

    x = yes/(yes+no)
    y = no/(yes+no)
    if x != 0 and y != 0:
        entropy = -1 * (x*math.log2(x) + y*math.log2(y))
    if x == 1:
        ans = 1
    if y == 1:
        ans = 0
    return entropy, ans


def findMaxGain(data, rows, columns):
    maxGain = 0
    retidx = -1
    entropy, ans = findEntropy(data, rows)
    if entropy == 0:
        """if ans == 1:
            print("Yes")
        else:
            print("No")"""
        return maxGain, retidx, ans

    for j in columns:
        mydict = {}
        idx = j
        for i in rows:
            key = data[i][idx]
            if key not in mydict:
                mydict[key] = 1
            else:
                mydict[key] = mydict[key] + 1
        gain = entropy

        # print(mydict)
        for key in mydict:
            yes = 0
            no = 0
            for k in rows:
                if data[k][j] == key:
                    if data[k][-1] == 'Yes':
                        yes = yes + 1
                    else:
                        no = no + 1
            # print(yes, no)
            x = yes/(yes+no)
            y = no/(yes+no)
            # print(x, y)
            if x != 0 and y != 0:
                gain += (mydict[key] * (x*math.log2(x) + y*math.log2(y)))/14
        # print(gain)
        if gain > maxGain:
            # print("hello")
            maxGain = gain
            retidx = j

    return maxGain, retidx, ans


def buildTree(data, rows, columns):
    maxGain, idx, ans = findMaxGain(X, rows, columns)
    gain.append(maxGain)
    root = Node()
    root.childs = []
    # print(maxGain
    #
    # )
    if maxGain == 0:
        if ans == 1:
            root.value = 'Yes'
        else:
            root.value = 'No'
        return root

    root.value = attribute[idx]
    mydict = {}
    for i in rows:
        key = data[i][idx]
        if key not in mydict:
            mydict[key] = 1
        else:
            mydict[key] += 1

    newcolumns = copy.deepcopy(columns)
    newcolumns.remove(idx)
    for key in mydict:
        newrows = []
        for i in rows:
            if data[i][idx] == key:
                newrows.append(i)
        # print(newrows)
        temp = buildTree(data, newrows, newcolumns)
        temp.decision = key
        root.childs.append(temp)
    return root


def traverse(root):
    print(root.decision)
    l.append(root.decision)
    l.append(root.value)
    print(root.value)

    n = len(root.childs)
    if n > 0:
        for i in range(0, n):
            traverse(root.childs[i])


def calculate():
    rows = [i for i in range(0, 14)]
    columns = [i for i in range(0, 4)]
    root = buildTree(X, rows, columns)
    root.decision = 'Start'
    traverse(root)
calculate()
del l[0]
from graphviz import Digraph
dot = Digraph(comment='A Simple Tree')
dot.node('A', l[0])
dot.node('B', l[1])
dot.node('C', l[2])
dot.node('D', l[3])
dot.node('E', l[4])
dot.node('F', l[5])
dot.node('G', l[6])
dot.node('H', l[7])
dot.node('I', l[8])
dot.node('J', l[9])
dot.node('K', l[10])
dot.node('L', l[11])
dot.node('M', l[12])
dot.node('N', l[13])
dot.node('O', l[14])
dot.edges(['AB', 'AH','AJ','BC','CD','CF','DE','DG','HI','JK','KN','KL','NO','LM'])
#print(dot.source)
dot.render('tree.gv', view=True)
